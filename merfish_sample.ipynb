{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f037e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcb2a63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "\n",
    "GlobalHydra.instance().clear()\n",
    "# setup hydra config global for loading this notebook\n",
    "hydra.initialize(config_path=\"configs\", version_base=None)\n",
    "cfg = hydra.compose(config_name=\"merfish_deconv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41bf3b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:53:38 - INFO - Using device: cuda\n",
      "21:53:40 - INFO - Using compile: False\n",
      "21:53:40 - INFO - Found checkpoint: /orcd/data/omarabu/001/njwfish/counting_flows/outputs/fd5d7615cb7a/model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4358 groups\n",
      "Found 77435 images that are smaller than or equal to 256\n",
      "Found 4790 groups\n",
      "Found 88483 images that are smaller than or equal to 256\n",
      "Found 9148 groups\n",
      "Found 165918 images that are smaller than or equal to 256\n",
      "Padding images to {img_size} x {img_size}\n",
      "Processing images completed\n",
      "attention mode is flash\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from main import setup_environment, get_checkpoint_info, is_training_complete\n",
    "\n",
    "# Setup environment\n",
    "device = setup_environment(cfg)\n",
    "\n",
    "# Get checkpoint info\n",
    "output_dir, checkpoint = get_checkpoint_info(cfg, num_epochs=cfg.training.num_epochs)\n",
    "\n",
    "# Instantiate everything\n",
    "bridge = hydra.utils.instantiate(cfg.bridge)\n",
    "dataset = hydra.utils.instantiate(cfg.dataset)\n",
    "model = hydra.utils.instantiate(cfg.model)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "avg_model = hydra.utils.instantiate(cfg.averaging, model=model)\n",
    "avg_model.load_state_dict(checkpoint['avg_model_state_dict'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7acaecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from training_deconv import sparse_aggregation_collate_fn\n",
    "\n",
    "\n",
    "max_batch_size = 10_000\n",
    "\n",
    "dl = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    "    collate_fn=lambda x: sparse_aggregation_collate_fn(x, max_batch_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c918240",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/143 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 143/143 [40:08<00:00, 16.84s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from training_deconv import deconv_sample_batch\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "x_0_generated = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dl):\n",
    "        x_1, context, sampler_kwargs = deconv_sample_batch(batch, device=device, condition_on_end_time=True)\n",
    "        x_0_generated.append(\n",
    "            bridge.sampler(\n",
    "                x_1, context, avg_model.module.to(device) if avg_model is not None else model, \n",
    "                **sampler_kwargs\n",
    "            )\n",
    "        )\n",
    "        if x_1['counts'].shape[0] == 10_000:\n",
    "            raise Exception(\"Max batch size reached\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bb713c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p results/merfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9130235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a30c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save x_0_generated\n",
    "import pickle\n",
    "with open('results/merfish/x_0_generated.pkl', 'wb') as f:\n",
    "    pickle.dump(x_0_generated, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
